{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1385a145",
   "metadata": {},
   "source": [
    "# Package Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69016e",
   "metadata": {},
   "source": [
    "## graph-tool installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc488b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T13:04:50.811346Z",
     "start_time": "2023-07-20T13:04:50.808128Z"
    }
   },
   "outputs": [],
   "source": [
    "#on windows: \n",
    "#use the windows key\n",
    "#type anaconda\n",
    "#open the anaconda power prompt as ADMINISTRATOR (right click). \n",
    "#conda activate base\n",
    "#conda create -n myenv python=3.8. \n",
    "#conda install -c conda-forge graph-tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91b5a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:40.958476Z",
     "start_time": "2023-08-25T08:49:40.941973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yil1/opt/anaconda3/envs/P2P/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check your python installation\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73307d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:43.742195Z",
     "start_time": "2023-08-25T08:49:43.730629Z"
    }
   },
   "outputs": [],
   "source": [
    "def install_missing_packages(package_names):\n",
    "    \"\"\"\n",
    "    Install Missing Packages\n",
    "\n",
    "    This function checks if a list of packages is already installed and installs any missing packages using pip.\n",
    "\n",
    "    Parameters:\n",
    "    - package_names (list): A list of package names to be installed.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    Note: This function requires the `subprocess` and `importlib` modules to be imported.\n",
    "\n",
    "    Example Usage:\n",
    "    install_missing_packages(['h2o', 'numpy', 'pandas'])\n",
    "    \"\"\"\n",
    "    import importlib\n",
    "    import subprocess\n",
    "\n",
    "\n",
    "    for package_name in package_names:\n",
    "        try:\n",
    "            importlib.import_module(package_name)\n",
    "            print(f\"{package_name} package is already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"{package_name} package not found, installing with pip...\")\n",
    "            subprocess.call(['pip', 'install', package_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818fc30d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:44.269883Z",
     "start_time": "2023-08-25T08:49:44.264101Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "package_list = []\n",
    "install_missing_packages(package_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be0d53",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d384247",
   "metadata": {},
   "source": [
    "## First-satge data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6c989c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:47.645166Z",
     "start_time": "2023-08-25T08:49:45.833362Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "clean_data(df):\n",
    "This code defines a function called `clean_data`, which takes a DataFrame (usually a DataFrame object in the pandas library) as input and performs a series of data cleaning operations on it. The specific cleaning steps are as follows:\n",
    "\n",
    "1. **Delete missing values**: Use the `dropna()` method to remove rows containing missing values.\n",
    "\n",
    "2. **Filter specific rows**: keep the rows whose `lang.1` column is equal to 1, and reset the index.\n",
    "\n",
    "3. **Delete 'lang' column**: Delete all columns containing \"lang\".\n",
    "\n",
    "4. **Delete Date Columns**: Delete `date.start` and `date.end` columns as they are considered irrelevant.\n",
    "\n",
    "5. **Remove Look-Bias Variables**: Define a list containing look-ahead-bias variables and use the `drop()` method to drop those columns from the DataFrame.\n",
    "\n",
    "6. **Delete Duplicate Income Variables**: Delete all columns that contain \"inc.\" and do not contain \".no\".\n",
    "\n",
    "7. **Delete Dummy Variables**: Defines a list of dummy variables to delete and removes these columns from the DataFrame.\n",
    "\n",
    "8. **Generate Correlation Matrix**: Use the `corr()` method to generate the correlation matrix of DataFrame.\n",
    "\n",
    "9. **Choose the upper triangle of the correlation matrix**: To avoid multicollinearity, select the upper triangle of the correlation matrix.\n",
    "\n",
    "10. **Find High Correlation Columns**: Find columns that have a correlation higher than 0.95 with other columns.\n",
    "\n",
    "11. **Delete High Correlation Columns**: Delete the high correlation columns found in step 10.\n",
    "\n",
    "Finally, the function returns the cleaned DataFrame.\n",
    "\n",
    "The purpose of this code is to prepare the data for subsequent analysis or modeling. It cleans data by removing missing values, filtering specific rows, removing irrelevant or biased columns, and handling multicollinearity.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import random\n",
    "\n",
    "# Define a function to calculate variance inflation factor (VIF) for all variables in a given DataFrame.\n",
    "def calculate_vif(df):\n",
    "    \"\"\"Calculates variance inflation factor for all columns in df. It should contain \n",
    "    only exogeneous variables.\"\"\"\n",
    "    \n",
    "    # Create an empty DataFrame\n",
    "    vif = pd.DataFrame()\n",
    "    \n",
    "    # Calculate VIF for every column (variable) in the DataFrame\n",
    "    vif[\"VIF Factor\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    \n",
    "    # Store column names\n",
    "    vif[\"features\"] = df.columns\n",
    "    \n",
    "    # Sort by VIF Factor in descending order\n",
    "    vif = vif.sort_values(\"VIF Factor\", ascending=False)\n",
    "    return vif\n",
    "\n",
    "# Define a function to clean the DataFrame, removing irrelevant and problematic features.\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean the given DataFrame, drop unnecessary columns, handle missing data, remove biased variables, \n",
    "    avoid multicollinearity by checking correlation, and keep only relevant columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Filter for only rows where 'lang.1' equals 1, and drop 'lang' columns\n",
    "    df = df[df[\"lang.1\"] == 1].reset_index(drop=True)\n",
    "    df = df.drop([x for x in df.columns if \"lang\" in x], axis=1)\n",
    "\n",
    "    # Drop date columns as they are not considered relevant\n",
    "    df = df.drop([\"date.start\", \"date.end\"], axis=1)\n",
    "\n",
    "    # List of forward-looking biased variables\n",
    "    fwl_bias = [\n",
    "        \"return\",\n",
    "        \"RR1\",\n",
    "        \"RR2.Mean\",\n",
    "        \"RR2.Median\",\n",
    "        \"RR2.WMean\",\n",
    "        \"NPRP\",\n",
    "        \"NPRA\",\n",
    "        \"FVCI\",\n",
    "        \"FVCI.Mean\",\n",
    "        \"FVCI.Median\",\n",
    "        \"FVCI.WMean\",\n",
    "    ]\n",
    "    # Drop these forward-looking biased variables\n",
    "    df = df.drop(fwl_bias, axis=1)\n",
    "\n",
    "    # Drop duplicate income variables, keep only those with '.no' in name\n",
    "    df = df.drop([x for x in df.columns if \"inc.\" in x and \".no\" in x], axis=1)\n",
    "\n",
    "    # List of dummy variables to drop\n",
    "    dummies_to_drop = [\"AA\", \"educ.6\", \"em.dur.5p\", \"use.m\", \"ver.2\", \"Mining\", \"Utilities\"]\n",
    "    df = df.drop(dummies_to_drop, axis=1)\n",
    "\n",
    "    # Generate a correlation matrix of the DataFrame\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    \n",
    "    # Drop these columns from the DataFrame\n",
    "    df = df.drop(df[to_drop], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_balanced_sample(df, n, replace = False):\n",
    "    \"\"\"Create a balanced sample of size 2n from df. Ensures that the sample contains an equal number of instances for each class.\"\"\"\n",
    "    \n",
    "    # Draw a random sample of size 'n' from the non-default class (default = 0) and from the default class (default = 1)\n",
    "    # replace=True allows for resampling\n",
    "    # Random state ensures reproducibility\n",
    "    df_sample = pd.concat(\n",
    "        [\n",
    "            df[df[\"default\"] == 0].sample(n=n, random_state=1, replace=replace),\n",
    "            df[df[\"default\"] == 1].sample(n=n, random_state=1, replace=replace),\n",
    "        ]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return df_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c6b7c",
   "metadata": {},
   "source": [
    "## Pands dataframe handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c9608b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:15:39.115064Z",
     "start_time": "2023-08-25T09:15:39.106000Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_category(df):\n",
    "    \"\"\"\n",
    "    Convert columns with exactly two unique values to category type.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): Input DataFrame to process.\n",
    "        \n",
    "    Returns:\n",
    "        df (pandas.DataFrame): Processed DataFrame with columns converted to category type where applicable.\n",
    "        category_columns (list): List of names of the columns that were converted to category type.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to store the names of the columns converted to category type\n",
    "    category_columns = []\n",
    "\n",
    "    # Iterate through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # If the column has exactly two unique values\n",
    "        if df[col].nunique() == 2:\n",
    "            # Convert the column to category type\n",
    "            df[col] = df[col].astype('category')\n",
    "            # Append the column name to the category_columns list\n",
    "            category_columns.append(col)\n",
    "\n",
    "    return df, category_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d0554",
   "metadata": {},
   "source": [
    "## File IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010f5859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:50.309876Z",
     "start_time": "2023-08-25T08:49:50.299529Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_file_path(file_name):\n",
    "    \"\"\"\n",
    "    Generate a file path for a file located one directory level up.\n",
    "\n",
    "    Parameters:\n",
    "    file_name (str): The name of the file including any subdirectories from the parent directory.\n",
    "\n",
    "    Returns:\n",
    "    file_path (str): The full path to the file.\n",
    "    \"\"\"\n",
    "    # Get the current working directory\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # Get the parent directory\n",
    "    parent_dir = os.path.dirname(cwd)\n",
    "\n",
    "    # Define the file path by joining the parent directory path with the file name\n",
    "    file_path = os.path.join(parent_dir, file_name)\n",
    "\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb1c610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:50.729878Z",
     "start_time": "2023-08-25T08:49:50.725057Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to save a pandas dataframe as csv to disc.\n",
    "def save_df_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    This function saves a pandas DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to save.\n",
    "    file_path (str): The file path where to save the DataFrame, including the filename.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)  # Set index=False to not save row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8116cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:53.281302Z",
     "start_time": "2023-08-25T08:49:53.269341Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_summary_stats(df, cols):\n",
    "    \"\"\"\n",
    "    This function computes summary statistics for specified columns in a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The dataframe on which to compute summary statistics.\n",
    "    cols (list): A list of column names for which to compute summary statistics.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A dataframe with summary statistics for the specified columns.\n",
    "\n",
    "    Example:\n",
    "    summary_stats = compute_summary_stats(df, ['liab.I', 'inc.total', 'MonthlyPayment', 'log.amount', 'time', 'Interest', 'AmountOfPreviousLoansBeforeLoan', 'NoOfPreviousLoansBeforeLoan', 'Age'])\n",
    "    print(summary_stats)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if all columns exist in dataframe\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            print(f'Column {col} does not exist in the dataframe.')\n",
    "            return None\n",
    "\n",
    "    # Compute summary statistics\n",
    "    summary_stats = df[cols].describe()\n",
    "\n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b26031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:53.720676Z",
     "start_time": "2023-08-25T08:49:53.712485Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_latex(df):\n",
    "    \"\"\"\n",
    "    This function converts a pandas DataFrame into a LaTeX table.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The dataframe to convert to LaTeX.\n",
    "\n",
    "    Returns:\n",
    "    str: A string of LaTeX code for a table with the data from the DataFrame.\n",
    "\n",
    "    Example:\n",
    "    latex_code = df_to_latex(summary_stats)\n",
    "    print(latex_code)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert DataFrame to LaTeX\n",
    "    latex_code = df.to_latex()\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82950439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:49:55.055664Z",
     "start_time": "2023-08-25T08:49:55.043142Z"
    }
   },
   "outputs": [],
   "source": [
    "# retrieving the number of non-defaulted vs. defaulted loans\n",
    "def count_defaults(df):\n",
    "    \"\"\"\n",
    "    This function counts and prints the number of defaulted loans in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing the loan data. It must contain a 'default' column \n",
    "                    with binary values: 1 for default and 0 otherwise.\n",
    "\n",
    "    Returns:\n",
    "    None. The function directly prints the number of defaulted loans.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_defaults = df['default'].sum()\n",
    "    print(f\"The number of loans that have defaulted is: {num_defaults}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2936d98",
   "metadata": {},
   "source": [
    "## Calculate and save gowers distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19655a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:29:55.700779Z",
     "start_time": "2023-08-25T09:29:55.686475Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gower\n",
    "\n",
    "\n",
    "def calculate_and_save_gowers_distance(dataframe, output_file_path):\n",
    "    \"\"\"\n",
    "    Calculates Gower's distance matrix for a given DataFrame and saves the result as a numpy array.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pandas.DataFrame): The input DataFrame.\n",
    "    output_file_path (str): The path where the resulting numpy array should be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Drop the 'default' column to keep only features\n",
    "        dataframe = dataframe.drop([\"Status\"], axis=1)\n",
    "\n",
    "        # Identify dummy columns (faster for gower calculations)\n",
    "        dummy_columns = [\n",
    "            column for column in dataframe.columns\n",
    "            if ((dataframe[column] == 0) | (dataframe[column] == 1)).all()\n",
    "        ]\n",
    "        categorical_variables = [\n",
    "            column in dummy_columns for column in dataframe.columns\n",
    "        ]\n",
    "\n",
    "        # Calculate Gower's distance\n",
    "        distance_matrix = gower.gower_matrix(\n",
    "            dataframe, cat_features=categorical_variables)\n",
    "\n",
    "        # Save the distance matrix as a numpy array\n",
    "        np.save(output_file_path, distance_matrix)\n",
    "\n",
    "        print(f\"Distance matrix saved successfully at {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "# Changes made:\n",
    "\n",
    "# 1. Renamed the function to `calculate_and_save_gowers_distance` for clarity.\n",
    "# 2. Added a try-except block to handle potential errors during execution.\n",
    "# 3. Added comments to explain each step of the process.\n",
    "# 4. Improved the print statement to include the output file path for better tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52260458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:57:23.698137Z",
     "start_time": "2023-08-25T08:57:22.283033Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graph_tool.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e7761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:57:23.722782Z",
     "start_time": "2023-08-25T08:57:23.722775Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_to_graph_tool(adj):\n",
    "    \"\"\"\n",
    "    Convert adjacency matrix to graph using graph-tool.\n",
    "\n",
    "    Parameters:\n",
    "    adj (numpy.ndarray): The adjacency matrix.\n",
    "\n",
    "    Returns:\n",
    "    g (graph_tool.Graph): The graph.\n",
    "    \"\"\"\n",
    "    # Extract index and weights from the adjacency matrix.\n",
    "    # np.nonzero(np.triu(adj, 1)) returns the indices of the upper triangle of the matrix,\n",
    "    # excluding the diagonal. This is because for an undirected graph, the adjacency matrix\n",
    "    # is symmetric, and we only need to consider half of the matrix to get all the edges.\n",
    "    idx = np.nonzero(np.triu(adj, 1))\n",
    "\n",
    "    # Get the weights of the edges from the adjacency matrix.\n",
    "    weights = adj[idx]\n",
    "\n",
    "    # Create an empty graph.\n",
    "    g = Graph()\n",
    "\n",
    "    # Add edges to the graph. np.transpose(idx) gives a 2D array where each row is the indices\n",
    "    # of the two vertices of an edge.\n",
    "    g.add_edge_list(np.transpose(idx))\n",
    "\n",
    "    # Create an edge property map for the weights of the edges.\n",
    "    edge_weight = g.new_edge_property(\"double\")\n",
    "\n",
    "    # Assign the weights to the edge property map.\n",
    "    edge_weight.a = weights\n",
    "\n",
    "    # Add the edge property map to the graph.\n",
    "    g.edge_properties[\"edge_weight\"] = edge_weight\n",
    "\n",
    "    return g\n",
    "\n",
    "def calculate_centrality_measures(g):\n",
    "    \"\"\"\n",
    "    Calculate various centrality measures for the graph.\n",
    "\n",
    "    Parameters:\n",
    "    g (graph_tool.Graph): The graph.\n",
    "\n",
    "    Returns:\n",
    "    df (pandas.DataFrame): DataFrame with centrality measures.\n",
    "    \"\"\"\n",
    "    # Calculate PageRank centrality. This measure reflects the importance of a node in the graph.\n",
    "    # Nodes with a high PageRank centrality are those that are well connected or connected to well-connected nodes.\n",
    "    pr_w = pagerank(g, weight=g.ep.edge_weight).a\n",
    "\n",
    "    # Calculate betweenness centrality. This measure reflects the amount of control that a node exerts over the interactions of other nodes in the graph.\n",
    "    # Nodes with high betweenness centrality are those that lie on many shortest paths between other nodes.\n",
    "    bw_w = betweenness(g, weight=g.ep.edge_weight)[0].a\n",
    "\n",
    "    # Calculate closeness centrality. This measure reflects how close a node is to all other nodes in the graph.\n",
    "    # Nodes with high closeness centrality can reach other nodes quickly.\n",
    "    cl_w = closeness(g, weight=g.ep.edge_weight).a\n",
    "\n",
    "    # Calculate eigenvector centrality. This measure reflects the influence of a node in a network.\n",
    "    # Nodes with high eigenvector centrality are those connected to many nodes who themselves have high centrality.\n",
    "    ev_w = eigenvector(g, weight=g.ep.edge_weight)[1].a\n",
    "\n",
    "    # Calculate Katz centrality. This measure is a generalization of degree centrality and eigenvector centrality.\n",
    "    kt_w = katz(g, weight=g.ep.edge_weight).a\n",
    "\n",
    "    # Calculate HITS authority and hub scores. The HITS algorithm computes two numbers for a node: \n",
    "    # Authorities estimates the node value based on the incoming links. \n",
    "    # Hubs estimates the node value based on outgoing links.\n",
    "    hits_aut_w = hits(g, weight=g.ep.edge_weight)[1].a\n",
    "    hits_hub_w = hits(g, weight=g.ep.edge_weight)[2].a\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"pagerank\": pr_w,\n",
    "        \"betweenness\": bw_w,\n",
    "        \"closeness\": cl_w,\n",
    "        \"eigenvector\": ev_w,\n",
    "        \"katz\": kt_w,\n",
    "        \"authority\": hits_aut_w,\n",
    "        \"hub\": hits_hub_w,\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313f65f",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac750499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:57:26.396463Z",
     "start_time": "2023-08-25T08:57:26.384462Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def data_sampling(df_sample, train=0.6, validation=0.2, test=0.2, random_state=8):\n",
    "    \"\"\"\n",
    "    This function calculates the row indices for train, validation, and test splits \n",
    "    based on the given proportions.\n",
    "\n",
    "    Parameters:\n",
    "    - df_sample: The input pandas DataFrame.\n",
    "    - train: Proportion of data for training. Default is 0.6.\n",
    "    - validation: Proportion of data for validation. Default is 0.2.\n",
    "    - test: Proportion of data for testing. Default is 0.2.\n",
    "    - random_state: Random seed for reproducibility. Default is 8.\n",
    "\n",
    "    Returns:\n",
    "    - train_indices: Row indices for the training split.\n",
    "    - validation_indices: Row indices for the validation split.\n",
    "    - test_indices: Row indices for the test split.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the input DataFrame is empty.\n",
    "    if df_sample.empty:\n",
    "        raise ValueError(\"The input DataFrame is empty!\")\n",
    "\n",
    "    # Validate if the sum of train, validation, and test proportions equals 1.\n",
    "    if not (train + validation + test == 1.0):\n",
    "        raise ValueError(\"The sum of train, validation, and test proportions should be 1.0\")\n",
    "\n",
    "    # Shuffle the row indices.\n",
    "    np.random.seed(random_state)\n",
    "    shuffled_indices = np.random.permutation(df_sample.index)\n",
    "\n",
    "    # Calculate the number of rows for each split.\n",
    "    total_rows = len(df_sample)\n",
    "    train_end = int(total_rows * train)\n",
    "    validation_end = train_end + int(total_rows * validation)\n",
    "\n",
    "    # Split the shuffled indices based on the calculated sizes.\n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    validation_indices = shuffled_indices[train_end:validation_end]\n",
    "    test_indices = shuffled_indices[validation_end:]\n",
    "\n",
    "    return train_indices, validation_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b4936",
   "metadata": {},
   "source": [
    "## Centrality Measures Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bd703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3d98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a30cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6298fd6e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3522e83",
   "metadata": {},
   "source": [
    "Read the raw data from bondora.\n",
    "Do some preprocessing\n",
    "Save it as cleaned data in feather format.\n",
    "Then sample a subset and save as cvs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a297154",
   "metadata": {},
   "source": [
    "The 1st round feature elimination happens here: Simply remove some features irrelevant to prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64968278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:58:16.948619Z",
     "start_time": "2023-08-25T08:58:15.416339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/p2p-model-bondora/data/Bondora_feather\n"
     ]
    }
   ],
   "source": [
    "# Load original dataset\n",
    "file_path = generate_file_path(\"data/Bondora_feather\")\n",
    "print(file_path)\n",
    "# Load the dataset\n",
    "df = pd.read_feather(file_path)\n",
    "\n",
    "# Clean data\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "# Save cleaned data\n",
    "file_path_cleaned = generate_file_path(\"data/Bondora_clean.feather\")\n",
    "df_clean.to_feather(file_path_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bcae6da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:58:18.018224Z",
     "start_time": "2023-08-25T08:58:18.007024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32469, 155)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfab23a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:58:25.651062Z",
     "start_time": "2023-08-25T08:58:25.633376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "0.0    20241\n",
       "1.0    12228\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['default'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d6e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:46:31.485878Z",
     "start_time": "2023-08-14T14:46:31.481449Z"
    }
   },
   "source": [
    "#Here, we create a varible to control sample size\n",
    "num_default_samples=12000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770b14e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:46:34.157507Z",
     "start_time": "2023-08-14T14:46:34.112718Z"
    }
   },
   "source": [
    "# Create balanced sample and save\n",
    "df_sample = create_balanced_sample(df_clean, num_default_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fccad2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T08:59:30.359197Z",
     "start_time": "2023-08-25T08:59:30.354070Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sample = df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce50678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:07:26.739536Z",
     "start_time": "2023-08-14T14:07:26.700568Z"
    }
   },
   "source": [
    "#save the file\n",
    "file_path_cleaned_sampled = generate_file_path(\n",
    "    \"data/Bondora_sample(\"+str(num_default_samples*2)+\").feather\")\n",
    "df_sample.to_feather(file_path_cleaned_sampled)\n",
    "print(file_path_cleaned_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32f2cb13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:07:28.407351Z",
     "start_time": "2023-08-14T14:07:28.367610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>new</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Interest</th>\n",
       "      <th>MonthlyPayment</th>\n",
       "      <th>DebtToIncome</th>\n",
       "      <th>NoOfPreviousLoansBeforeLoan</th>\n",
       "      <th>AmountOfPreviousLoansBeforeLoan</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>no.previous.loan.04</th>\n",
       "      <th>no.previous.loan.05</th>\n",
       "      <th>no.previous.loan.06</th>\n",
       "      <th>no.previous.loan.07</th>\n",
       "      <th>no.previous.repay.00</th>\n",
       "      <th>no.previous.repay.01</th>\n",
       "      <th>previous.repay.l</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.85</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.41</td>\n",
       "      <td>3.433342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>4.794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.36</td>\n",
       "      <td>3.794815</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>4.797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.12</td>\n",
       "      <td>3.684118</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>12120.0</td>\n",
       "      <td>4.798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.63</td>\n",
       "      <td>5.477802</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5021.0</td>\n",
       "      <td>4.798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.49</td>\n",
       "      <td>3.004692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>9221.0</td>\n",
       "      <td>4.802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.969791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32469 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       default  new  Age  Gender  Interest  MonthlyPayment  DebtToIncome  \\\n",
       "0          1.0    1   30     1.0     28.00        0.000000         19.11   \n",
       "1          1.0    1   39     0.0     28.00        0.000000         45.22   \n",
       "2          1.0    1   32     0.0     28.00        0.000000         44.86   \n",
       "3          0.0    1   27     0.0     19.00        0.000000         10.70   \n",
       "4          0.0    0   31     0.0     16.00        0.000000         15.85   \n",
       "...        ...  ...  ...     ...       ...             ...           ...   \n",
       "32464      0.0    0   22     0.0     18.41        3.433342          0.00   \n",
       "32465      0.0    1   29     0.0     16.36        3.794815          0.00   \n",
       "32466      0.0    0   32     0.0     17.12        3.684118          0.00   \n",
       "32467      0.0    0   46     1.0     25.63        5.477802          0.00   \n",
       "32468      0.0    0   45     0.0     22.49        3.004692          0.00   \n",
       "\n",
       "       NoOfPreviousLoansBeforeLoan  AmountOfPreviousLoansBeforeLoan   time  \\\n",
       "0                                0                              0.0  1.846   \n",
       "1                                0                              0.0  1.845   \n",
       "2                                0                              0.0  1.846   \n",
       "3                                0                              0.0  1.846   \n",
       "4                                1                           3000.0  1.840   \n",
       "...                            ...                              ...    ...   \n",
       "32464                            5                           9886.0  4.794   \n",
       "32465                            1                           1275.0  4.797   \n",
       "32466                            3                          12120.0  4.798   \n",
       "32467                            3                           5021.0  4.798   \n",
       "32468                            7                           9221.0  4.802   \n",
       "\n",
       "       ...  no.previous.loan.04  no.previous.loan.05  no.previous.loan.06  \\\n",
       "0      ...                  0.0                  0.0                  0.0   \n",
       "1      ...                  0.0                  0.0                  0.0   \n",
       "2      ...                  0.0                  0.0                  0.0   \n",
       "3      ...                  0.0                  0.0                  0.0   \n",
       "4      ...                  0.0                  0.0                  0.0   \n",
       "...    ...                  ...                  ...                  ...   \n",
       "32464  ...                  0.0                  1.0                  0.0   \n",
       "32465  ...                  0.0                  0.0                  0.0   \n",
       "32466  ...                  0.0                  0.0                  0.0   \n",
       "32467  ...                  0.0                  0.0                  0.0   \n",
       "32468  ...                  0.0                  0.0                  0.0   \n",
       "\n",
       "       no.previous.loan.07  no.previous.repay.00  no.previous.repay.01  \\\n",
       "0                      0.0                   1.0                   0.0   \n",
       "1                      0.0                   1.0                   0.0   \n",
       "2                      0.0                   1.0                   0.0   \n",
       "3                      0.0                   1.0                   0.0   \n",
       "4                      0.0                   1.0                   0.0   \n",
       "...                    ...                   ...                   ...   \n",
       "32464                  0.0                   1.0                   0.0   \n",
       "32465                  0.0                   1.0                   0.0   \n",
       "32466                  0.0                   1.0                   0.0   \n",
       "32467                  0.0                   1.0                   0.0   \n",
       "32468                  1.0                   0.0                   1.0   \n",
       "\n",
       "       previous.repay.l  A  B  C  \n",
       "0              0.000000  0  1  0  \n",
       "1              0.000000  0  1  0  \n",
       "2              0.000000  0  0  1  \n",
       "3              0.000000  0  0  1  \n",
       "4              0.000000  1  0  0  \n",
       "...                 ... .. .. ..  \n",
       "32464          0.000000  0  1  0  \n",
       "32465          0.000000  0  1  0  \n",
       "32466          0.000000  0  1  0  \n",
       "32467          0.000000  0  0  1  \n",
       "32468          6.969791  0  0  1  \n",
       "\n",
       "[32469 rows x 155 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating data frame for the entire datasample\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e8a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:01:31.456623Z",
     "start_time": "2023-08-25T09:01:30.589437Z"
    }
   },
   "source": [
    "#save the pandas.dataframe \"df_clean\" as csv.\n",
    "file_path_full_data = generate_file_path(\"data/Bondora_clean.csv\")\n",
    "print(file_path_full_data)\n",
    "#Usage of the function\n",
    "save_df_to_csv(df_clean, file_path_full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ad2266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:01:42.189850Z",
     "start_time": "2023-08-25T09:01:42.161979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>new</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Interest</th>\n",
       "      <th>MonthlyPayment</th>\n",
       "      <th>DebtToIncome</th>\n",
       "      <th>NoOfPreviousLoansBeforeLoan</th>\n",
       "      <th>AmountOfPreviousLoansBeforeLoan</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>no.previous.loan.04</th>\n",
       "      <th>no.previous.loan.05</th>\n",
       "      <th>no.previous.loan.06</th>\n",
       "      <th>no.previous.loan.07</th>\n",
       "      <th>no.previous.repay.00</th>\n",
       "      <th>no.previous.repay.01</th>\n",
       "      <th>previous.repay.l</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.85</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.41</td>\n",
       "      <td>3.433342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>9886.0</td>\n",
       "      <td>4.794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.36</td>\n",
       "      <td>3.794815</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>4.797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.12</td>\n",
       "      <td>3.684118</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>12120.0</td>\n",
       "      <td>4.798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.63</td>\n",
       "      <td>5.477802</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5021.0</td>\n",
       "      <td>4.798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.49</td>\n",
       "      <td>3.004692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>9221.0</td>\n",
       "      <td>4.802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.969791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32469 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       default  new  Age  Gender  Interest  MonthlyPayment  DebtToIncome  \\\n",
       "0          1.0    1   30     1.0     28.00        0.000000         19.11   \n",
       "1          1.0    1   39     0.0     28.00        0.000000         45.22   \n",
       "2          1.0    1   32     0.0     28.00        0.000000         44.86   \n",
       "3          0.0    1   27     0.0     19.00        0.000000         10.70   \n",
       "4          0.0    0   31     0.0     16.00        0.000000         15.85   \n",
       "...        ...  ...  ...     ...       ...             ...           ...   \n",
       "32464      0.0    0   22     0.0     18.41        3.433342          0.00   \n",
       "32465      0.0    1   29     0.0     16.36        3.794815          0.00   \n",
       "32466      0.0    0   32     0.0     17.12        3.684118          0.00   \n",
       "32467      0.0    0   46     1.0     25.63        5.477802          0.00   \n",
       "32468      0.0    0   45     0.0     22.49        3.004692          0.00   \n",
       "\n",
       "       NoOfPreviousLoansBeforeLoan  AmountOfPreviousLoansBeforeLoan   time  \\\n",
       "0                                0                              0.0  1.846   \n",
       "1                                0                              0.0  1.845   \n",
       "2                                0                              0.0  1.846   \n",
       "3                                0                              0.0  1.846   \n",
       "4                                1                           3000.0  1.840   \n",
       "...                            ...                              ...    ...   \n",
       "32464                            5                           9886.0  4.794   \n",
       "32465                            1                           1275.0  4.797   \n",
       "32466                            3                          12120.0  4.798   \n",
       "32467                            3                           5021.0  4.798   \n",
       "32468                            7                           9221.0  4.802   \n",
       "\n",
       "       ...  no.previous.loan.04  no.previous.loan.05  no.previous.loan.06  \\\n",
       "0      ...                  0.0                  0.0                  0.0   \n",
       "1      ...                  0.0                  0.0                  0.0   \n",
       "2      ...                  0.0                  0.0                  0.0   \n",
       "3      ...                  0.0                  0.0                  0.0   \n",
       "4      ...                  0.0                  0.0                  0.0   \n",
       "...    ...                  ...                  ...                  ...   \n",
       "32464  ...                  0.0                  1.0                  0.0   \n",
       "32465  ...                  0.0                  0.0                  0.0   \n",
       "32466  ...                  0.0                  0.0                  0.0   \n",
       "32467  ...                  0.0                  0.0                  0.0   \n",
       "32468  ...                  0.0                  0.0                  0.0   \n",
       "\n",
       "       no.previous.loan.07  no.previous.repay.00  no.previous.repay.01  \\\n",
       "0                      0.0                   1.0                   0.0   \n",
       "1                      0.0                   1.0                   0.0   \n",
       "2                      0.0                   1.0                   0.0   \n",
       "3                      0.0                   1.0                   0.0   \n",
       "4                      0.0                   1.0                   0.0   \n",
       "...                    ...                   ...                   ...   \n",
       "32464                  0.0                   1.0                   0.0   \n",
       "32465                  0.0                   1.0                   0.0   \n",
       "32466                  0.0                   1.0                   0.0   \n",
       "32467                  0.0                   1.0                   0.0   \n",
       "32468                  1.0                   0.0                   1.0   \n",
       "\n",
       "       previous.repay.l  A  B  C  \n",
       "0              0.000000  0  1  0  \n",
       "1              0.000000  0  1  0  \n",
       "2              0.000000  0  0  1  \n",
       "3              0.000000  0  0  1  \n",
       "4              0.000000  1  0  0  \n",
       "...                 ... .. .. ..  \n",
       "32464          0.000000  0  1  0  \n",
       "32465          0.000000  0  1  0  \n",
       "32466          0.000000  0  1  0  \n",
       "32467          0.000000  0  0  1  \n",
       "32468          6.969791  0  0  1  \n",
       "\n",
       "[32469 rows x 155 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354d7a3",
   "metadata": {},
   "source": [
    "# Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac516398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:06:15.886005Z",
     "start_time": "2023-08-25T09:06:15.874521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Status', 'new', 'Age', 'Gender', 'Interest', 'MonthlyPayment', 'DebtToIncome', 'NoOfPreviousLoansBeforeLoan', 'AmountOfPreviousLoansBeforeLoan', 'time', 'Hour.0', 'Hour.1', 'Hour.2', 'Hour.3', 'Hour.4', 'Hour.5', 'Hour.6', 'Hour.7', 'Hour.8', 'Hour.9', 'Hour.10', 'Hour.11', 'Hour.12', 'Hour.13', 'Hour.14', 'Hour.15', 'Hour.16', 'Hour.17', 'Hour.18', 'Hour.19', 'Hour.20', 'Hour.21', 'Hour.22', 'weekday.1', 'weekday.2', 'weekday.3', 'weekday.4', 'weekday.5', 'weekday.6', 'ver.3', 'ver.4', 'log.amount', 'duration.06', 'duration.09', 'duration.12', 'duration.18', 'duration.24', 'duration.36', 'duration.48', 'duration.60', 'use.0', 'use.1', 'use.2', 'use.3', 'use.4', 'use.5', 'use.6', 'use.7', 'use.8', 'educ.2', 'educ.3', 'educ.4', 'educ.5', 'marital.1', 'marital.2', 'marital.3', 'marital.4', 'marital.5', 'depen.0', 'depen.1', 'depen.2', 'depen.3', 'depen.4', 'employ.2', 'employ.3', 'employ.4', 'employ.5', 'employ.6', 'em.dur.other', 'em.dur.ret', 'em.dur.trial', 'em.dur.1y', 'em.dur.2y', 'em.dur.3y', 'em.dur.4y', 'em.dur.5y', 'exper.02y', 'exper.05y', 'exper.10y', 'exper.15y', 'exper.25y', 'exper.25p', 'Other', 'Processing', 'Energy', 'Construction', 'Retail.wholesale', 'Transport.warehousing', 'Hospitality.catering', 'Info.telecom', 'Finance.insurance', 'Real.estate', 'Research', 'Administrative', 'Civil.service.military', 'Education', 'Healthcare.social.help', 'Art.entertainment', 'Agriculture.for.fish', 'homeless', 'owner', 'livingw.parents', 'tenant.pfp', 'council.house', 'joint.tenant', 'joint.ownership', 'mortgage', 'encumbrance', 'inc.princ.empl.l', 'inc.pension.l', 'inc.fam.all.l', 'inc.soc.wel.l', 'inc.leave.l', 'inc.child.l', 'inc.other.l', 'inc.total', 'no.liab.00', 'no.liab.01', 'no.liab.02', 'no.liab.03', 'no.liab.04', 'no.liab.05', 'no.liab.10', 'liab.l', 'no.refin.00', 'no.refin.01', 'no.refin.02', 'no.refin.03', 'no.refin.04', 'inc.support', 'FreeCash.l', 'no.previous.loan.00', 'no.previous.loan.01', 'no.previous.loan.02', 'no.previous.loan.03', 'no.previous.loan.04', 'no.previous.loan.05', 'no.previous.loan.06', 'no.previous.loan.07', 'no.previous.repay.00', 'no.previous.repay.01', 'previous.repay.l', 'A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "# Get a copy of the column names\n",
    "columns = df_sample.columns.tolist()\n",
    "\n",
    "# Change the name of the first column\n",
    "columns[0] = 'Status'\n",
    "\n",
    "# Reassign the changed column names to the DataFrame\n",
    "df_sample.columns = columns\n",
    "print(df_sample.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ac79db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:18:27.658596Z",
     "start_time": "2023-08-25T09:18:27.598614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Status', 'new', 'Gender', 'Hour.0', 'Hour.1', 'Hour.2', 'Hour.3', 'Hour.4', 'Hour.5', 'Hour.6', 'Hour.7', 'Hour.8', 'Hour.9', 'Hour.10', 'Hour.11', 'Hour.12', 'Hour.13', 'Hour.14', 'Hour.15', 'Hour.16', 'Hour.17', 'Hour.18', 'Hour.19', 'Hour.20', 'Hour.21', 'Hour.22', 'weekday.1', 'weekday.2', 'weekday.3', 'weekday.4', 'weekday.5', 'weekday.6', 'ver.3', 'ver.4', 'duration.06', 'duration.09', 'duration.12', 'duration.18', 'duration.24', 'duration.36', 'duration.48', 'duration.60', 'use.0', 'use.1', 'use.2', 'use.3', 'use.4', 'use.5', 'use.6', 'use.7', 'use.8', 'educ.2', 'educ.3', 'educ.4', 'educ.5', 'marital.1', 'marital.2', 'marital.3', 'marital.4', 'marital.5', 'depen.0', 'depen.1', 'depen.2', 'depen.3', 'depen.4', 'employ.2', 'employ.3', 'employ.4', 'employ.5', 'employ.6', 'em.dur.other', 'em.dur.ret', 'em.dur.trial', 'em.dur.1y', 'em.dur.2y', 'em.dur.3y', 'em.dur.4y', 'em.dur.5y', 'exper.02y', 'exper.05y', 'exper.10y', 'exper.15y', 'exper.25y', 'exper.25p', 'Other', 'Processing', 'Energy', 'Construction', 'Retail.wholesale', 'Transport.warehousing', 'Hospitality.catering', 'Info.telecom', 'Finance.insurance', 'Real.estate', 'Research', 'Administrative', 'Civil.service.military', 'Education', 'Healthcare.social.help', 'Art.entertainment', 'Agriculture.for.fish', 'homeless', 'owner', 'livingw.parents', 'tenant.pfp', 'council.house', 'joint.tenant', 'joint.ownership', 'mortgage', 'encumbrance', 'no.liab.00', 'no.liab.01', 'no.liab.02', 'no.liab.03', 'no.liab.04', 'no.liab.05', 'no.liab.10', 'no.refin.00', 'no.refin.01', 'no.refin.02', 'no.refin.03', 'no.refin.04', 'no.previous.loan.00', 'no.previous.loan.01', 'no.previous.loan.02', 'no.previous.loan.03', 'no.previous.loan.04', 'no.previous.loan.05', 'no.previous.loan.06', 'no.previous.loan.07', 'no.previous.repay.00', 'no.previous.repay.01', 'A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "df_sample, category_columns = convert_to_category(df_sample)\n",
    "print(category_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "812583c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:28:08.123748Z",
     "start_time": "2023-08-25T09:28:08.111944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/p2p-model-bondora/data/Dist_matrix(32469).npy\n"
     ]
    }
   ],
   "source": [
    "dist_matrix_path = generate_file_path(\"data/Dist_matrix(\"+'32469'+\").npy\")\n",
    "print(dist_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad4dd662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-25T09:31:39.546771Z",
     "start_time": "2023-08-25T09:30:02.467642Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_and_save_gowers_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_matrix_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m, in \u001b[0;36mcalculate_and_save_gowers_distance\u001b[0;34m(dataframe, output_file_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m categorical_variables \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m     column \u001b[38;5;129;01min\u001b[39;00m dummy_columns \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate Gower's distance\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mgower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgower_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Save the distance matrix as a numpy array\u001b[39;00m\n\u001b[1;32m     35\u001b[0m np\u001b[38;5;241m.\u001b[39msave(output_file_path, distance_matrix)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/P2P/lib/python3.8/site-packages/gower/gower_dist.py:89\u001b[0m, in \u001b[0;36mgower_matrix\u001b[0;34m(data_x, data_y, weight, cat_features)\u001b[0m\n\u001b[1;32m     87\u001b[0m     j_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# call the main function\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgower_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mX_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mY_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_n_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mY_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_n_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_max\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m#print(res)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m out[i,j_start:]\u001b[38;5;241m=\u001b[39mres\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/P2P/lib/python3.8/site-packages/gower/gower_dist.py:111\u001b[0m, in \u001b[0;36mgower_get\u001b[0;34m(xi_cat, xi_num, xj_cat, xj_num, feature_weight_cat, feature_weight_num, feature_weight_sum, categorical_features, ranges_of_numeric, max_of_numeric)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgower_get\u001b[39m(xi_cat,xi_num,xj_cat,xj_num,feature_weight_cat,\n\u001b[1;32m    107\u001b[0m               feature_weight_num,feature_weight_sum,categorical_features,\n\u001b[1;32m    108\u001b[0m               ranges_of_numeric,max_of_numeric ):\n\u001b[1;32m    109\u001b[0m     \n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# categorical columns\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     sij_cat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi_cat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxj_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     sum_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(feature_weight_cat,sij_cat)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# numerical columns\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "distance_matrix = calculate_and_save_gowers_distance(df_sample, dist_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbe9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff713cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36fa0a0b",
   "metadata": {},
   "source": [
    "# Compute Gowers distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c263a3",
   "metadata": {},
   "source": [
    "Gower's distance is a measure of similarity between two data objects in a dataset. It was proposed by J.C. Gower in 1971 and is particularly useful when dealing with mixed data types, such as datasets that have a combination of numerical and categorical data.\n",
    "\n",
    "Gower's distance calculates the similarity between objects based on a radial basis function between each variable of the objects. For numerical variables, the individual variable difference between two objects is divided by the range of that variable. For categorical variables, the difference is 0 if the category is the same and 1 otherwise. The individual similarities are then combined into an overall similarity.\n",
    "\n",
    "\n",
    "If you're dealing with datasets that are purely numerical or categorical, there are other distance measures that might be more appropriate:\n",
    "\n",
    "For numerical data, you can use Euclidean distance, Manhattan distance, or Minkowski distance. These are available in the scipy.spatial.distance module.\n",
    "\n",
    "For categorical data, you can use Hamming distance or Jaccard similarity. Hamming distance is available in the scipy.spatial.distance module, and Jaccard similarity can be calculated using the sklearn.metrics.jaccard_score function.\n",
    "\n",
    "Remember, the choice of distance measure can significantly impact the results of your analysis, so it's important to understand the properties of each measure and choose the one that's most appropriate for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145d6b6",
   "metadata": {},
   "source": [
    "## Compute adjacency, distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0546341d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:42:11.099680Z",
     "start_time": "2023-08-14T13:42:11.075369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/p2p-model-bondora/data/Bondora_sample(24000).feather\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# Define the file path for the distance matrix\n",
    "sample_data_path = generate_file_path(\"data/Bondora_sample(\"+str(num_default_samples*2)+\").feather\")\n",
    "df_sample = pd.read_feather(sample_data_path)\n",
    "print(sample_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020113a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:44:41.034429Z",
     "start_time": "2023-08-14T13:44:41.034423Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_matrix_path = generate_file_path(\"data/Dist_matrix(\"+str(num_default_samples*2)+\").npy\")\n",
    "print(dist_matrix_path)\n",
    "distance_matrix = calculate_and_save_gowers_distance(df_sample, dist_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d058cab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:45:28.033180Z",
     "start_time": "2023-08-14T13:45:28.016539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.16073741, 0.16187109, ..., 0.15937716, 0.15014191,\n",
       "        0.1440083 ],\n",
       "       [0.16073741, 0.        , 0.14556302, ..., 0.08173035, 0.09980128,\n",
       "        0.08579823],\n",
       "       [0.16187109, 0.14556302, 0.        , ..., 0.19736263, 0.11842113,\n",
       "        0.08599633],\n",
       "       ...,\n",
       "       [0.15937716, 0.08173035, 0.19736263, ..., 0.        , 0.12556161,\n",
       "        0.12544167],\n",
       "       [0.15014191, 0.09980128, 0.11842113, ..., 0.12556161, 0.        ,\n",
       "        0.05349661],\n",
       "       [0.1440083 , 0.08579823, 0.08599633, ..., 0.12544167, 0.05349661,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4facaa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:45:34.806286Z",
     "start_time": "2023-08-14T13:45:34.797803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "003da515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:15:33.049011Z",
     "start_time": "2023-08-14T14:15:33.036462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c1cf5",
   "metadata": {},
   "source": [
    "What we have now:\n",
    "\n",
    "df_sample\n",
    "\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b03ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T13:48:31.514182Z",
     "start_time": "2023-08-14T13:48:31.503100Z"
    }
   },
   "source": [
    "# Sample segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7dabd829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:47:26.147225Z",
     "start_time": "2023-08-14T14:47:26.136125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [ 4043 14260 17854 ...  2452 22316   940]\n",
      "Validation indices: [ 8416 15510 11013 ...  8599  1879 21192]\n",
      "Test indices: [  725 10861  6246 ...  2181 18417  4547]\n"
     ]
    }
   ],
   "source": [
    "train_indices, validation_indices, test_indices = data_sampling(df_sample)\n",
    "print(f\"Train indices: {train_indices}\")\n",
    "print(f\"Validation indices: {validation_indices}\")\n",
    "print(f\"Test indices: {test_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af794258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:39:49.164074Z",
     "start_time": "2023-08-14T14:39:49.155238Z"
    }
   },
   "source": [
    "train_indices\n",
    "\n",
    "validation_indices\n",
    "\n",
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc1ad19f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:47:36.385041Z",
     "start_time": "2023-08-14T14:47:36.373226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4043, 14260, 17854, ...,  2452, 22316,   940])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4c17c19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:47:38.696323Z",
     "start_time": "2023-08-14T14:47:38.672078Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices_d, train_indices_nd = indices_dnd(df_sample, train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4227d73",
   "metadata": {},
   "source": [
    "train_indices_d\n",
    "\n",
    "train_indices_nd\n",
    "\n",
    "validation_indices\n",
    "\n",
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e817673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-14T14:51:18.318375Z",
     "start_time": "2023-08-14T14:51:18.302402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    set(\n",
    "        np.concatenate((train_indices_d, train_indices_nd, validation_indices,\n",
    "                        test_indices))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864c001",
   "metadata": {},
   "source": [
    "# Add centrality measures\n",
    "more on graph-tools.\n",
    "https://robert-haas.github.io/gravis-docs/code/examples/external_tools/graph-tool.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce5c011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:15:44.378338Z",
     "start_time": "2023-07-26T18:15:43.808027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load adjacency matrix\n",
    "# The adjacency matrix is a square matrix used to represent a finite graph.\n",
    "# The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.\n",
    "adj_path = generate_file_path(\"data/Dist_matrix(\"+str(num_default_samples*2)+\").npy\")\n",
    "adj = np.load(adj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a05fad",
   "metadata": {},
   "source": [
    "Explain: Here, this graph is a fully connected, which means each pair of nodes has an edge. Thus, the Adjacency Matrix is equivalent to the Gower's Distance Matrix.\n",
    "\n",
    "(When a graph is not fully connected, these two matrix are not equivalent any more.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b0d4d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:16:20.352845Z",
     "start_time": "2023-07-26T18:16:04.119388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert adjacency matrix to graph\n",
    "# The adjacency matrix is then converted into a graph object using the `matrix_to_graph_tool` function.\n",
    "# This function takes the adjacency matrix as input and returns a graph object that can be manipulated using the `graph-tool` library.\n",
    "g = matrix_to_graph_tool(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b53de",
   "metadata": {},
   "source": [
    "Attention here! We can use alpha threathold here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a808b8e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:23:19.116912Z",
     "start_time": "2023-07-26T18:16:26.407744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate minimum spanning tree and set as edge filter\n",
    "# A minimum spanning tree (MST) of a graph is a subset of the edges of the graph that connects all the vertices together,\n",
    "# without any cycles and with the minimum possible total edge weight.\n",
    "# The `min_spanning_tree` function from the `graph-tool` library is used to calculate the MST.\n",
    "# The resulting MST is then set as an edge filter on the graph using `g.set_edge_filter(tree)`.\n",
    "# This means that only the edges that are part of the MST will be considered in subsequent operations on the graph.\n",
    "tree = min_spanning_tree(g, weights=g.ep.edge_weight)\n",
    "g.set_edge_filter(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cd2d11d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T14:15:01.757318Z",
     "start_time": "2023-07-20T14:15:00.739855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph object, directed, with 24000 vertices and 23999 edges, 1 internal edge property, edges filtered by (<EdgePropertyMap object with value type 'bool', for Graph 0x2ab455e80, at 0x17ff403a0>, False), vertices filtered by (<VertexPropertyMap object with value type 'bool', for Graph 0x2ab455e80, at 0x17ab72c10>, False), at 0x2ab455e80>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a447ea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:34:15.896726Z",
     "start_time": "2023-07-26T18:33:14.494676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate centrality measures\n",
    "# Finally, several centrality measures are calculated for the graph using the `calculate_centrality_measures` function.\n",
    "# Centrality measures provide a way of identifying the most important vertices within a graph.\n",
    "# They are commonly used in network analysis to determine the relative importance of a vertex within the graph.\n",
    "# The resulting centrality measures are stored in a DataFrame.\n",
    "centrality_df = calculate_centrality_measures(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2e5b39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:34:33.518667Z",
     "start_time": "2023-07-26T18:34:33.499690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>closeness</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>authority</th>\n",
       "      <th>hub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.902073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.078653e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.976149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.410830e-83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.396533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.701703e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.359868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.883548e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.029100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.762067e-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>6.289251e-103</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>3.161870e-142</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>5.968064e-126</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>4.234108e-49</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>1.081868e-80</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pagerank  betweenness  closeness  eigenvector      katz      authority  \\\n",
       "0      0.000023          0.0   8.902073          NaN  0.006453   0.000000e+00   \n",
       "1      0.000023          0.0  15.976149          NaN  0.006453   0.000000e+00   \n",
       "2      0.000023          0.0  13.396533          NaN  0.006453   0.000000e+00   \n",
       "3      0.000023          0.0   7.359868          NaN  0.006453   0.000000e+00   \n",
       "4      0.000023          0.0  26.029100          NaN  0.006453   0.000000e+00   \n",
       "...         ...          ...        ...          ...       ...            ...   \n",
       "23995  0.000127          0.0        NaN          NaN  0.006456  6.289251e-103   \n",
       "23996  0.000078          0.0        NaN          NaN  0.006454  3.161870e-142   \n",
       "23997  0.000184          0.0        NaN          NaN  0.006455  5.968064e-126   \n",
       "23998  0.000034          0.0        NaN          NaN  0.006454   4.234108e-49   \n",
       "23999  0.000131          0.0        NaN          NaN  0.006456   1.081868e-80   \n",
       "\n",
       "                hub  \n",
       "0      2.078653e-22  \n",
       "1      2.410830e-83  \n",
       "2      6.701703e-47  \n",
       "3      3.883548e-67  \n",
       "4      1.762067e-95  \n",
       "...             ...  \n",
       "23995  0.000000e+00  \n",
       "23996  0.000000e+00  \n",
       "23997  0.000000e+00  \n",
       "23998  0.000000e+00  \n",
       "23999  0.000000e+00  \n",
       "\n",
       "[24000 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "489a1c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T14:23:02.567975Z",
     "start_time": "2023-07-20T14:23:02.562956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(centrality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc739f5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:34:44.404495Z",
     "start_time": "2023-07-26T18:34:43.765195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column eigenvector only contains NaN values. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "def plot_histogram(df, column):\n",
    "    \"\"\"\n",
    "    å¯¹äºŽæ¯åˆ—ï¼Œç»˜åˆ¶ç›´æ–¹å›¾ã€‚\n",
    "    å¦‚æžœè¿™ä¸€åˆ—å…¨æ˜¯NaNï¼Œè¾“å‡ºè­¦å‘Šå¹¶è·³è¿‡ã€‚\n",
    "    \"\"\"\n",
    "    if df[column].isna().all(): # å¦‚æžœåˆ—å…¨æ˜¯NaNå€¼ï¼Œè¾“å‡ºè­¦å‘Šå¹¶è·³è¿‡\n",
    "        print(f\"Warning: Column {column} only contains NaN values. Skipping...\")\n",
    "        return\n",
    "\n",
    "    plt.figure()\n",
    "    sns.histplot(df[column], kde=False, bins=50) # é™åˆ¶binsæ•°é‡ä¸º50\n",
    "    plt.title(f\"Histogram of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "centrality_data_path = generate_file_path(\"graph/Bondora_centrality_sample(\"+str(num_default_samples*2)+\").pdf\")\n",
    "\n",
    "with PdfPages(centrality_data_path) as pdf: # è¾“å‡ºè‡³PDF\n",
    "    for column in centrality_df.columns:\n",
    "        plot_histogram(centrality_df, column)\n",
    "        if plt.get_fignums():  # æ£€æŸ¥æ˜¯å¦æœ‰æ´»åŠ¨çš„figure\n",
    "            pdf.savefig()  # å°†å½“å‰figureä¿å­˜åˆ°pdfä¸­\n",
    "            plt.close()    # å…³é—­å½“å‰figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971cd0c1",
   "metadata": {},
   "source": [
    "## Combine ans save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3af8b54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:34:49.154448Z",
     "start_time": "2023-07-26T18:34:49.132865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/p2p-model-bondora/data/Bondora_sample(24000).feather\n"
     ]
    }
   ],
   "source": [
    "# Load original dataset\n",
    "sample_data_path = generate_file_path(\"data/Bondora_sample(\"+str(num_default_samples*2)+\").feather\")\n",
    "df_sample = pd.read_feather(sample_data_path)\n",
    "print(sample_data_path)\n",
    "\n",
    "# Merge with original dataset\n",
    "df_sample_with_centrality = pd.concat([df_sample, centrality_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8311e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T18:34:50.856150Z",
     "start_time": "2023-07-26T18:34:50.088616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yil1/p2p-model-bondora/data//Bondora_sample(24000)_with_centrality.csv\n"
     ]
    }
   ],
   "source": [
    "df = df_sample_with_centrality\n",
    "\n",
    "# Define the text file path\n",
    "txt_file_path = generate_file_path(\"data//Bondora_sample(\"+str(num_default_samples*2)+\")_with_centrality.csv\")\n",
    "print(txt_file_path)\n",
    "# Write the DataFrame to the text file\n",
    "df.to_csv(txt_file_path, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07090795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "æ— ",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.505432px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
